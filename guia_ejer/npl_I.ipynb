{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 1 <br>\n",
    "Dada la siguiente tabla de Count Vectorizer:\n",
    "\n",
    "|  \t  | Car | Dog | Police | Gun |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| D1 | 0 | 1 | 2 | 5 |\n",
    "| D2 | 2 | 1 | 1 | 4 |\n",
    "| D3 | 1 | 0 | 0 | 0 |\n",
    "\n",
    "Devolver el documento que menos distancia coseno tenga con la query: <br>\n",
    "“Police officer accidentally discharge their gun while eating a donut. Car survives.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tabla es Term Frequency (Count Vertorizer)\n",
    "la query: “Police officer accidentally discharge their gun while eating a donut. Car survives.”\n",
    "\n",
    "|  \t  | Car | Dog | Police | Gun |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| query | 1 | 0 | 1 | 1 |\n",
    "\n",
    "Aplicamos la similitud coseno entre la query y cada documento:\n",
    "\n",
    "||cos($\\theta$)|\n",
    "|---|---|\n",
    "|D1|$\\frac{7}{\\sqrt{90}}$ = 0.737|\n",
    "|D2|$\\frac{7}{\\sqrt{66}}$ = 0.861|\n",
    "|D3|$\\frac{1}{\\sqrt{3}}$ = 0.5477|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El documento más similar es D2 con una similitud de coseno de 0.8616404368553292\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Definir la matriz de Count Vectorizer para los documentos\n",
    "document_matrix = np.array([\n",
    "    [0, 1, 2, 5],\n",
    "    [2, 1, 1, 4],\n",
    "    [1, 0, 0, 0]\n",
    "])\n",
    "\n",
    "# Definir la consulta como un vector de Count Vectorizer\n",
    "query_vector = np.array([1, 0, 1, 1])\n",
    "\n",
    "# Calcular la similitud del coseno entre la consulta y los documentos\n",
    "cosine_similarities = cosine_similarity([query_vector], document_matrix)\n",
    "\n",
    "# Obtener el índice del documento con la mayor similitud del coseno\n",
    "most_similar_document_index = np.argmax(cosine_similarities)\n",
    "\n",
    "# Imprimir el documento más similar\n",
    "print(f\"El documento más similar es D{most_similar_document_index + 1} con una similitud de coseno de {cosine_similarities[0][most_similar_document_index]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados los siguientes documentos:\n",
    "```python\n",
    "D1: news about organic food campaign\n",
    "D2: news of presidential campaign\n",
    "D3: news of presidential campaign, presidential candidate\n",
    "D4: news of presidential campaign presidential candidate\n",
    "D5: news of organic food campaign campaign campaign campaign\n",
    "```\n",
    "Si nuestra consulta es “news about presidential campaign” y usamos TF-IDF: <br>\n",
    "Calcule los vectores de cada documento y de la consulta y encuentre el documento más cercano. <br>\n",
    "Cómo cambia usando CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El documento más cercano usando TF-IDF es D1: news about organic food campaign\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Documentos\n",
    "documents = [\n",
    "    \"news about organic food campaign\",\n",
    "    \"news of presidential campaign\",\n",
    "    \"news of presidential campaign, presidential candidate\",\n",
    "    \"news of presidential campaign presidential candidate\",\n",
    "    \"news of organic food campaign campaign campaign campaign\"\n",
    "]\n",
    "\n",
    "# Consulta\n",
    "query = \"news about presidential campaign\"\n",
    "\n",
    "# Crear el vectorizador TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Ajustar y transformar los documentos y la consulta\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "query_vector = tfidf_vectorizer.transform([query])\n",
    "\n",
    "# Calcular la similitud del coseno entre la consulta y los documentos\n",
    "cosine_similarities = cosine_similarity(query_vector, tfidf_matrix)\n",
    "\n",
    "# Encontrar el documento más cercano\n",
    "most_similar_document_index = cosine_similarities.argmax()\n",
    "most_similar_document = documents[most_similar_document_index]\n",
    "\n",
    "print(f\"El documento más cercano usando TF-IDF es D{most_similar_document_index + 1}: {most_similar_document}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando CountVectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El documento más cercano usando CountVectorizer es D2: news of presidential campaign\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Crear el vectorizador CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Ajustar y transformar los documentos y la consulta\n",
    "count_matrix = count_vectorizer.fit_transform(documents)\n",
    "query_vector = count_vectorizer.transform([query])  # Transformar la query a vector\n",
    "\n",
    "# Calcular la similitud del coseno entre la consulta y los documentos\n",
    "cosine_similarities = cosine_similarity(query_vector, count_matrix)\n",
    "\n",
    "# Encontrar el documento más cercano\n",
    "most_similar_document_index = cosine_similarities.argmax()\n",
    "most_similar_document = documents[most_similar_document_index]\n",
    "\n",
    "print(f\"El documento más cercano usando CountVectorizer es D{most_similar_document_index + 1}: {most_similar_document}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza un proceso de normalización para las palabras de un texto, dadas las siguientes transformaciones indique si son producto de stemming, de lemmatization o de ambas:\n",
    "\n",
    "- puertas -> puerta\n",
    "- corromper -> corromp\n",
    "- altitudes -> altitud\n",
    "- delta -> delta\n",
    "\n",
    "Respuesta: <br>\n",
    "- puertas -> puerta: stemming\n",
    "- corromper -> corromp: stemming\n",
    "- altitudes -> altitud: lemmatization\n",
    "- delta -> delta: lemmatization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
